\documentclass[]{report}
\usepackage[margin=1in]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{url}
\usepackage{todonotes}
\usepackage{ytableau}

\ytableausetup{centertableaux}

% Environments

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}

\numberwithin{theorem}{section}
\numberwithin{equation}{section}

%Commands
\newcommand{\tr}{\operatorname{Tr}}
\newcommand{\res}{\operatorname{Res}}
\newcommand{\ind}{\operatorname{Ind}}
\newcommand{\im}{\operatorname{im}}

\newcommand{\Span}{\operatorname{span}}
\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\doublefaktor}[3]{% 
	{\textstyle #1}
	\mkern-4mu\scalebox{1.5}{$\diagdown$}\mkern-5mu^{\textstyle #2}%
	\mkern-4mu\scalebox{1.5}{$\diagup$}\mkern-5mu{\textstyle #3} }

%opening
\title{Representation theory Notes}
\author{Eric Luu}

\begin{document}

\maketitle
\section{Representations}
A representation of a group $G$ on a vector space $V$ is a map $\rho : G \rightarrow GL(V)$ where $\rho_{g}: V \rightarrow V$ and $\rho_{1} = id$ and $\rho_{g}\rho_{h} x = \rho_{gh} x$. The degree of $\rho$ is dim $V$. The vector spaces that we will be working over are finite-dimensional vector spaces over $\mathbb{C}$, and the groups are finite.

\subsection{Examples}
\begin{enumerate}
	\item Trivial representation: $g \mapsto Id_V$.
	\item Sign representation: $\rho: S_n \rightarrow \mathbb{C}^*$ where $g \mapsto \text{sign}(g)$. 
	\item Natural representation of $S_n \rightarrow GL_n(\mathbb{C})$:
	$g(e_i) = e_{g(i)}$ for $i = 1, 2, ..., n$. The set of permutation matrices of the identity matrix.
	\item Regular representation: For a set $G$, let $V = \text{span}\lbrace e_h : h \in G \rbrace$. Then $\rho_g(e_h) = e_{gh}$ is the left regular representation.
\end{enumerate}
We say that two representations $\rho^1: G \rightarrow GL(V_1)$ and $\rho^2: G \rightarrow GL(V_2)$ are equivalent if there exists an isomorphism $T: V_1 \rightarrow V_2$ such that $\rho^2_g = T \rho^{1}_g T^{-1}$.
\section{Irreducible and indecomposible}
We say a subspace $U \leq V$ is $\rho$-invariant under a representation $\rho: G \rightarrow GL(V)$ if $\rho_g(u) \in U$ for all $u \in U$ and $g \in G$, or in terms of actions, the orbit space of $U$ is $U$. Restricting $\rho$ to $U$ is a subrepresentation.
$\rho: G \rightarrow GL(V)$ is irreducible if the only invariant subspaces are trivial, and reducible otherwise. We say that $V$ is decomposable if $V = V_1 \oplus V_2$ for non-zero invariant subspaces, and indecomposible otherwise.
Note that decomposable implies reducible, and irreducible implies decomposable. Completely reducible implies that we can decompose $V$ into direct sum of subspaces $V_i$ where the representation on $V_i$ is irreducible. 

\begin{theorem}[Matschke's theorem]
	Every representation of a finite group over $\mathbb{C}$ is completely reducible. 
\end{theorem}


We need this lemma to prove Matschke's theorem.

\begin{lemma}
	Let $\rho : G \rightarrow GL(V)$ be a unitary representation, where $G$ is any group and $V$ is over $\mathbb{C}$. Then $\rho$ is irreducible or decomposible. 
\end{lemma}
\begin{proof}
	Consider $\langle \cdot , \cdot \rangle$ as the standard inner product on $V$. We can construct a inner product
	$\langle v,w \rangle_\rho = \sum_{g \in G} \langle \rho_g v , \rho_g w \rangle$
	such that $\rho$ is unitary.
	
Suppose $V$ is unitary. Then $V$ is decomposable. We look at the orthogonal complement of the nontrivial subspace and show that under $\langle \cdot, \cdot \rangle_\rho$, $U^\bot$ is invariant. 

Take $g \in G$, $u \in U$, and $v \in U^\bot$. 
Then:
\begin{equation}
	\langle \rho_g(v), u \rangle = \langle \rho_{g^{-1}} \rho_g v, \rho_{g^{-1}} u \rangle = \langle \rho v, \rho_{g^{-1}} u \rangle = 0
\end{equation}
as $v$ is in $U^\bot$ and $\rho_{g^{-1}} u$ is in $U$. Thus shown decomposability. 
\end{proof}

\begin{proof}[Proof of Matschke's theorem]
	Suppose $\rho$ is a non-zero rep. Then it is equivalent to a unitary rep, so $\rho$ is irreducible or decomposable. Now we induct on the dimension. If $\dim V = 1$, then $V$ is irreducible. This handles the base case. Suppose it holds for all $\dim V < n$. Then if $V$ has dimension $n + 1$, and $V$ is not irreducible, then $V$ must be decomposable. So $V = U \oplus W$ for invariant subspaces $U$ and $W$. By induction, $U$ and $W$ are completely reducible. Therefore, $V$ is also completely reducible.
\end{proof}
Noe that Matschke's theorem only works when $\langle v,w \rangle_\rho = \sum_{g \in G} \langle \rho_g v , \rho_g w \rangle$ is well-defined. We can use integration over compact groups (matrix integrals) to have similar results. 


\begin{theorem}[Schur's lemma]
	Suppose $\rho$ and $\psi$ be irreducible representations over $\mathbb{C}$. Then the only homomorphisms between $\rho$ and $\psi$ are null-homeomorphisms or scaled isomorphisms. 
\end{theorem}

We use two lemmas to prove this. 
Let $Hom_G( \rho, \psi)$ be the set of morphisms from $\rho$ to $\psi$. We have that:
\begin{lemma}
	$Hom_G( \rho, \psi)$ is a subspace of $Hom(V, W)$. This is because if $S, T \in Hom_G(\rho, \psi)$, $a, b \in \mathbb{C}$, then $(a S + b T) \rho_g = a S \rho_g + b T \rho_g = a \psi_g S + b \psi_g T = \psi_g (a S + b T)$. Additionally, the zero map is in $Hom_G( \rho, \psi)$. 
\end{lemma}

We also have that $\ker T$ is $\rho$-invariant subspace of $V$, and $\im T$ is a $\psi$-invariant subspace of $W$.
\begin{proof}
	$T \rho_g v = \psi_g T v = \psi_g 0 = 0$. Similarly, if $w \in \im T$ then $w = T v$ for some $v \in V$. Then $\psi_g W = \psi_g T v = T \rho_g v$ is in im T. Thus shown.
\end{proof}

\begin{proof}
	Let $T \in Hom_G( \rho, \psi)$. Since $\ker T$ is $\rho$-invariant and $\rho$ is an irrep, $\ker T = 0$ or $V$. We also have that since im $T$ is $\psi$-invariant and $\psi$ is an irrep, then $\im T = 0$ or $W$. Therefore, $T$ is either the zero map or is an isomorphism. Then we have that if $T$ is an isomorphism, then $\rho \sim \psi$. 
	
	As we are working over $\mathbb{C}$, $T$ has eigenvalue $\lambda$. THen $\lambda I - T$ is not invertible. But we have that $\lambda I - T \in Hom_G(\rho, \rho)$. But this means that $\lambda I - T = 0$, so $T = \lambda I$. 
\end{proof}

By Schur's lemma, all abelian groups have dimension 1. 

\section{Algebraic constructions}
\subsection{New constructions}
We have that if $V$ and $W$ are vector spaces, then the direct sum $V \oplus W$ is a vector space where every element is of the form $v \oplus w$, and obeys the laws that $v_1 \oplus w_1 + v_2 \oplus w_2 = (v_1 + v_2) \oplus (w_1 + w_2)$ and $c (v_1 \oplus w_1) = (c v_1) \oplus (c w_1)$. 

The tensor product $V \otimes W$ is the vector space where $(v_1 + v_2) \otimes w = v_1 \otimes w + v_2 \otimes w$, $v \otimes (w_1 + w_2) = v \otimes w_1 + v \otimes w_2$, $c (v \otimes w) = (cv) \otimes w = v \otimes (cw)$. 

We say $V^{\otimes k}$ to be the tensor product of $v$ with itself $k$ times. 

\subsection{Algebras}
A ring is a structure with an addition and multiplication operator. We have that:
$R$ is an abelian group under addition, so:
\begin{itemize}
	\item $(a + b) + c = a + (b + c)$
	\item $a + b = b + a$
	\item there is an identity such that $a + 0 = a$ for all $a$ in $\mathbb{R}$.
	\item For all $a$ there exists a $-a$ such that $a - a = 0$. 
\end{itemize}
$R$ is a monoid under multiplication, so:
\begin{itemize}
	\item $(a \times b) \times c = a \times (b \times c)$
	\item There exists a $1$ such that $a \times 1 = a = 1 \times a$.
\end{itemize}
Finally, these elements work together nicely, so
\begin{itemize}
	\item $a \times (b + c) = a \times b + a \times c$
	\item $(b + c) \times a = b \times a + c \times a$. 
\end{itemize}

A field is a commutative (so $a \times b = b \times a$) ring where $0 \neq 1$ and all nonzero elements are invertible under multiplication.

An algebra $A$ over a field $K$ is a vector space over $K$ with a bilinear product $A \times A \rightarrow A$ that is bilinear, where:
\begin{itemize}
	\item $(x + y) \cdot z = x \cdot z + y \cdot z$
	\item $x  \cdot (y + z) = x \cdot y + x \cdot z$.
	\item $(cx) \cdot y = x \cdot (cy) = c (x \cdot y)$.
\end{itemize}
We will also assume our algebras are associative, so $(x \cdot y) \cdot z = x \cdot (y \cdot z)$ and unital, so there is a $1 \in A$ such that $1 \cdot x = x \cdot 1 = x$.

\subsection{Examples}
\begin{itemize}
	\item $\mathbb{C}$ under multiplication
	\item $\mathbb{C}[t]$ = complex polynomials under polynomial multiplication
	\item $Mat_n(\mathbb{C})$ is the $n \times n$ complex matrices under matrix multiplication
	\item $\mathbb{C} G$ is a group algebra.
\end{itemize}

A module over a ring $R$ is an abelian group $M$ and an operation $R \times M \rightarrow M$ where:
\begin{itemize}
	\item $r \cdot (x + y) = r \cdot x + r \cdot y$
	\item $(r + s) \cdot x = r \cdot x + s \cdot x$
	\item $(rs )\cdot x = r \cdot (s \cdot x)$
	\item $1 \cdot x = x$
\end{itemize}
for $r, s \in R$, $x, y \in M$.

Essentially, we treat the algebra $A$ as the ring and $V$ as the abelian group to form an $A$-module. There is an algebra homomorphism $\tilde{\rho}: A \rightarrow End(V)$ and we write it as $a \cdot v$. 

The tensor algebra is:
\begin{equation}
	V^{\otimes 0} \oplus V^{\otimes 1} \oplus V^{\otimes 2} \oplus ...
\end{equation}

Finally, we have that reps $(\rho \otimes \phi))g(v \otimes w) = \rho_g(v) \otimes \rho_g(w)$. 

Symmetric power:

$Sym^k(V)$ is the quotient of $V^{\otimes k}$ by the relation $u \otimes v = v \otimes w$ for $u, v \in V$.

Then we have that the symmetric algebra of $V$ is:

\begin{equation}
	Sym^0(V) \oplus Sym^1(V) \oplus Sym^2(V) \oplus ... 
\end{equation}

The exterior power is $\bigwedge^k(V)$. This is $V^{\otimes k}$ with the relation $u \otimes v = -v \otimes u$.

We denote the exterior product as $u \wedge v$. 

The exterior algebra is:
\begin{equation}
	\bigwedge^0(V) \oplus \bigwedge^1(V) \oplus \bigwedge^2(V) \oplus ... 
\end{equation}

The dual space is the map of functionals on $V$.

We have that the dual representation is $\rho^*_g(f) (v) = f(\rho_{g^{-1}}(v)))$.

\subsection{Schur's lemma}
Let $U$ and $V$ be simple $A$-modules, where $A$ is an algebra over $\mathcal{C}$. Then the only homomorphisms between $U$ and $V$ are the null map, or a scaled isomorphism.

\begin{proof}
	Suppose $U$ and $V$ are $A$-modules. Then we have that for any map $T \in Hom_A(U, V)$, $T$ is a $U$, $V$ preserving map. $T : U \rightarrow V$.
	
	Let $u \in \ker(T)$, so $T v = 0$. But this means that $a \cdot T v = T (a \cdot v) = 0$, so $a \cdot v$ is in $\ker T$. We also have that if $v = T (u)$, then $a \cdot v = a \cdot T(u) = T( a \cdot u)$, so $a \cdot u$ is in $\im T$. Therefore, $T$ is $A$-invariant.
	
	Because of this, we have that as the $A$-module is simple, then $\ker T = 0$ or $U$. Similarly, $\im T = 0$ or $V$. Therefore, $T$ is either a zero map or an isomorphism.
	
	To show $T$ is a scaled isomorphism, let $\lambda \in \mathbb{C}$ and consider $T - \lambda I$. We have that for some $\lambda$ this is a zero map. Therefore, $T = \lambda I$. 
\end{proof}

\subsection{Group algebras}

The group algebra is the algebra that comes from linearising a group $G$. 

\section{Characters}
In mathematics, we can summarise data about a mathematical object that allows us to completely distinguish two objects from each other. One example is a moment-generating function. 

In representation theory, the summary data that we think about is characters.

\begin{definition}
	Let $\rho : G \rightarrow GL(V)$ be a rep over $\mathbb{C}$. Then the associated character $\chi_\rho : G \rightarrow \mathbb{C}$ is defined as $\chi_\rho(g) = tr(\rho_g)$. 
\end{definition}
Characters store the information about a representation!
If $\rho \sim \psi$, then $\chi_\rho = \chi_\psi$. 
\begin{proof}
	Suppose we have isomorphism $T: V \rightarrow W$. Then for $g \in G$, we have that:
	\begin{equation}
		\rho_g = T^{-1} \psi_g T
	\end{equation}
	so $\tr(\rho_g) = \tr(T^{-1} \psi_g T)$
\end{proof}
As $\tr(A B C) = \tr(C A B) = \tr(B C A)$, then $\tr(T^{-1} \psi_g T) = \tr(\psi_g)$. Therefore we have that $\chi_\rho = \chi_\psi$. 

Facts:
\begin{corollary}
	Let $\rho$, $\psi$ be reps. Then:
	\begin{enumerate}
		\item $\chi_{\rho \oplus \psi} = \chi_\rho + \chi_\psi$.
		\item $\chi_{\rho \otimes \psi} = \chi_\rho \times \chi_\psi$. 
		\item $\chi_\rho(1) = \deg \rho$. 
		\item $\chi_\rho(h g h^{-1}) = \chi_\rho(g)$.
		\item $\chi_\rho(g^{-1}) = \overline{\chi_\rho(g)}$ for $G$ finite. 
	\end{enumerate}
\end{corollary}
\begin{proof}
	\begin{enumerate}
		\item We have that $(\rho \oplus \psi)_g$ is a block matrix with $\rho_g$ and $\psi_g$ as the blocks on the diagonal. Then the trace is the sum of the traces of $\rho_g$ and $\psi_g$. 
		\item We have that $(\rho \otimes \psi)_g$ takes basis elements $v_i \otimes w_j$ to $\rho_g(v_i) \otimes \psi_g(w_j)$. Then let the basis of $V \otimes W$ to be the eigenbasis of $\rho_g$ and $\psi_g$, and the result follows from the basis of the tensor product.
		\item $\chi_\rho(1)$ is the trace of the identity matrix which is $1$. 
		\item As the trace has the rotation property and $\rho$ is a homomorphism, we have that $\tr(\rho_{h^{-1} g h}) = \tr(\rho_{h^{-1}} \rho_g \rho_h) = \tr( \rho_g)$. 
		\item We have that the trace is the sum of eigenvalues. We have that $\rho_g$ has eigenvalues $\lambda_i$ and its inverse has eigenvalues $\overline{\lambda_i}$, as the inverse is $\lambda^{|G| - 1} = 1 = \overline{\lambda}$. Then the sum of the conjugate eigenvalues is $\overline{\chi_\rho(g)}$. 
	\end{enumerate}
\end{proof}
This restricts what an irreducible character looks like- irreps have coresponding irreducible chracters. 

We can view class functions as elements in the group algebra $\mathbb{C}G$.

Orthogonal relations:
\begin{theorem}
	Irreducible characters of $G$ is the same as the conjugacy classes of $G$. 
	
	1st orthogonality relation:
	$\frac{1}{|G|} \sum_{g \in G} \chi_i(g) \overline{\chi_j(g)} = \langle \chi_i, \chi_j \rangle = 0$ for $i \neq j$.
	
	2nd orthogonality relation:
	$\sum_{i = 1}^{k} \chi_i(g) \overline{\chi_i(h)} = 0$ if $g$ and $h$ are in different conjugacy classes. 
\end{theorem}

This proof of the 1st orthogonality relation is from 3.19.
\begin{proof}
	Let $\phi : G \rightarrow GL_m(\mathbb{C})$ and $\psi : G \rightarrow GL_n(\mathbb{C})$ be representations of a finite group $G$. Let $V = Mat_{mn}(\mathbb{C})$ and define a representation $\rho: G \rightarrow GL(V)$ by $\rho_g(A) = \phi_g A \psi^*_g$ where $\psi^*$ is the conjugate transpose. 
	
	We have that $\chi_\rho(g) = \tr(\rho(g))$. We have that the trace of the operation is the multiplicity of the basis elements in this set. Let $E_{ij} \in Mat_{mn}(\mathbb{C})$ be the basis matrix, with $1$ in entry $[E]_{ij}$ and zeroes everywhere else. Then we have that $\phi_g E_{k \ell} \psi^*_g = \sum_{i = 1}^{m} \sum_{j = 1}^{n} \phi_{ik}(g) \psi^*_{j \ell}(g) E_{ij}$, meaning that the trace of this element will be $\phi_{k k} \psi^*_{\ell \ell}$. Then taking the sums of all elements, we have that:
	\begin{equation}
		\tr(\rho(g)) = \sum_{i = 1}^{m} \sum_{j = 1}^{n} \phi_{i,i}(g) \psi^*{j,j}(g) = \sum_{i = 1}^{m} \phi_{i,i}(g)\sum_{j = 1}^{n}  \psi^*{j,j}(g) = \tr(\phi(g)) \overline{\tr(\psi(g))} = \chi_\phi(g) \overline{\chi_\psi(g)}. 
	\end{equation}
	
	Now we have that homeomorphisms between $\psi$ and $\phi$ which preserve the group operation is precisely the fixed subspace $V^G$. Let $T$ be a homeomorphism between $\psi$ and $\phi$. Then we have that $\rho_g(T) = \phi_g T \psi^*_g = T \psi_g \psi^*_g = T$. Secondly, if $T$ is in the fixed subspace, then by working backwards, it is in the fixed subspace $V^G$. We have that the dimension of $Hom_G(\psi, \phi)$ is $1/|G| \sum_{h \in G} \tr(\rho_h)$, which is simply $1/|G| \sum_{g \in G} \chi_\phi(g) \overline{\chi_\psi(g)} = \left\langle \chi_\phi, \chi_\psi \right\rangle$. But from Schur's lemma, we have that $Hom_G(\psi, \phi)$ has dimension zero or 1, and it has dimension $0$ if $\phi \nsim \psi$ and dimension $1$ if $\phi \sim \psi$. Therefore, the 1st orthogonality relation holds. 
	
\end{proof}
To prove the second orthogonality relation, we use a technical lemma.
\begin{lemma}[Technical lemma]
	Let $\rho : G \rightarrow GL(V)$ be an irrep and $f \in Z(L(G))$. Then:
	\begin{equation}
		\sum_{g \in G} \overline{f(g)} \rho(g) = \frac{|G|}{\deg(\rho)} \langle \chi_\rho, f \rangle Id_V. 
	\end{equation}
\end{lemma}

\begin{proof}
	Let $T = \sum_{g \in G} \overline{f(g)} \rho(g)$. Then for $h \in G$, we have that:
	\begin{align*}
		\rho_h T &= \rho_h \sum_{g \in G} \overline{f(g)} \rho_g\\
		 &=\sum_{g \in G} \overline{f(g)} \rho_{h g h^{-1}} \rho_h\\
		 &=\sum_{g \in G} \overline{f(h g h^{-1})} \rho_{h g h^{-1}} \rho_h\\
		 &=\sum_{x \in G} \overline{f(x)} \rho_{x} \rho_h\\
		 &= T \rho_h
	\end{align*}
	So $\rho_h T = T \rho_h$ for all $h \in G$. Therefore, $T \in Hom_G(\rho, \rho)$ and Schur's lemma applies. We have that $T = \lambda Id_V$ for some $\lambda \in \mathbb{C}$. Taking the trace of both sides, we have that:
	
	\begin{equation}
		\sum_{g \in G} \overline{f(g)} \chi_\rho(g) = |G| \langle \chi_\rho, f \rangle = \lambda \deg \rho 
	\end{equation}
	which implies above. 
\end{proof}

To show that $\chi_1, ..., \chi_s$ spans $Z(L(G))$, suppose not. Suppose there is an $f$ such that $\langle \chi_i, f \rangle = 0$ for all $1, 2, ..., s$. Then this implies that $\sum_{g \in G} \overline{f(g)} \lambda(g) = 0$, the zero map for all $\lambda$. In particular, this is zero when $\lambda$ is the regular representation. But suppose we have $h \in G$ is an element of $\mathbb{C}(G)$. We have that $\sum_{g \in G} \overline{f(g)} \lambda_g h = \sum_{g \in G} \overline{f(g)} gh = \sum_{x \in G} \overline{f(x h^{-1})} x = 0$. But this implies that as all $x$ are independent in $\mathbb{C}G$, then $f(x h^{-1}) = 0$ for all $x \in G$. But this means that $f$ is a zero map on $G$. Thus the only orthogonal map is the zero function, and $\chi_1, ..., \chi_s$ span $Z(L(G))$. 

Therefore, character tables are square. 

\begin{theorem}[Second orthogonality relation]
	Suppose $C, D \subseteq G$ be conjugacy classes with $g \in C$ and $h \in D$. Then:
	\begin{equation}
		\sum_{i = 1}^k \chi_i(g) \overline{\chi_i(h)} = \begin{cases}
			|G|/|C|, & \text{ if } C = D\\
			0, & \text{ if } C \neq D
		\end{cases}
	\end{equation}
\end{theorem}

\begin{proof}
	Since $\chi_1, \chi_2, ..., \chi_k$ is an orthonormal basis,
	
	\begin{align*}
		\delta_D(g) &= \sum_{i = 1}^k \langle \delta_D, \chi_i \rangle \chi_g\\
		&= \sum_{i = 1}^k \frac{1}{|G|} \sum_{h \in G} \delta_D(g) \overline{\chi_i(h)} \chi_i(g)\\
		&= \frac{1}{|G|}\sum_{i = 1}^k \sum_{h \in D} \overline{\chi_i(h)} \chi_i(g)\\
		&= \frac{|D|}{|G|}\sum_{i = 1}^k \overline{\chi_i(h)} \chi_i(g)
	\end{align*}
	But we have that by the definition of $\delta_D(g)$, we have that 
	\begin{equation}
		\frac{|D|}{|G|}\sum_{i = 1}^k \overline{\chi_i(h)} \chi_i(g) = \begin{cases}
			1, & \text{ if } g \in D\\
			0, & \text{ if } g \notin D
		\end{cases}
	\end{equation}
	which shows what we need. 
\end{proof}
\section{Topics on characters}

We say a character is ``real'' iff $\overline{\chi} = \chi$. We say a conjugacy class $C$ is real if it holds that $C^{-1} := \{g^{-1}: g \in C\}$ is $C$.

\begin{theorem}[Burnside's theorem]
	If $G$ is finite, the number of real irreducible characters equals the number of real conjugacy classes.
\end{theorem}

\begin{proof}
	Label the conjugacy classes $C_1, C_2, .., C_k$ and let $\chi_1, \chi_2, ..., \chi_k$ be the irreducible characters. Let $\alpha, \beta \in S_k$ by $\overline{\chi_i} = \chi_{\alpha(i)}$ and $C_i^{-1} = C_{\beta(i)}$.
	
	Then $\chi_i$ is real iff $\alpha_i = i$ and $C_i$ is real iff $\beta_i = i$.
	
	So we want to show that the number of fixed points in $\alpha$ and $\beta$ are the same. Now the number of fixed points in $S_n$ is $\tr(\rho_\sigma)$ where $\rho$ is the natural representation. So we want to show that
	\begin{equation}
		\tr(\rho_\alpha) = \tr(\rho_\beta).
	\end{equation}
	
	Let $\chi$ be the character table for $G$. We have that $\rho_\alpha(X)$ is obtained from $X$ by swapping $\chi_i$ and $\overline{\chi_i}$, which means that $\rho_\alpha(X) = \overline{X}$, and $\chi \rho_\beta = \overline{X}$ as we swap columns which are conjugates. Then as $X$ is invertible, we have that $\rho_\alpha = X \rho_\beta X^{-1}$ which implies that $\tr(\rho_\alpha) = \tr(\rho_\beta)$. 
\end{proof}


\section{Restriction and induction}

Suppose we have a class function $f: G \rightarrow \mathbb{C}$ and a subgroup $H \leq G$. Then we have that the restriction of $f$ onto $H$, denoted $\res^G_H f : H \rightarrow \mathbb{C}$ in the obvious way. 
\begin{equation}
	\res^G_H f(h) = f(h)
\end{equation}
for all $h \in H$. 

Now this is a class function because $f$ is a class function. Additionally, we send characters to characters. 
\subsection{Induction}
Suppose we have a class function $f: H \rightarrow \mathbb{C}$ and that $H \leq G$. Then consider $\dot{f}$, which does the following:
\begin{equation}
	\dot{f}(h) =
	\begin{cases}
		f(h) & h \in H\\
		0 & h \notin H
	\end{cases}.
\end{equation}
We have that $\dot{f}(h)$ is linear but not a class function.
Consider any class function $f: A_4 \rightarrow \mathbb{C}$ such that $(123)$ and $(132)$ have different values. Lift to $S_4$. Then $\dot{f}$ is not well defined on the conjugacy class $(123)$ so $\dot{f}$ is not a class function.
However, can we construct an induced class function from $f$? Yes. 

\begin{equation}
	Ind^G_H f(g) = \frac{1}{|H|} \sum_{x \in G} \dot{f}(x^{-1} g x)
\end{equation}
This is a class function. We have that:

\begin{equation}
	Ind^G_H f(y^{-1}g y) = \frac{1}{|H|} \sum_{x \in G} \dot{f}((yx)^{-1} g yx) = \frac{1}{|H|} \sum_{x \in G} \dot{f}(x^{-1} g x) = Ind^G_H f(g) 
\end{equation}
This is also linear by the linearity of $\dot{f}$. 

\subsection{Frobenius reciprocity}
For $H \leq G$, $a \in ZL(H)$, $b \in ZL(G)$, we have the following relation:
\begin{equation}
	\left\langle \ind^G_H a ,b \right\rangle = \left\langle a , Res^G_H b \right\rangle 
\end{equation}

\begin{proof}
	We have that:
	\begin{align*}
		\left\langle \ind^G_H a ,b \right\rangle &= 
		\frac{1}{|G|} \sum_{g \in G} \ind^G_H a(g) \overline{b(g)}\\
		&= \frac{1}{|G|} \sum_{g \in G} \frac{1}{|H|} \sum_{x \in G} \dot{f}(x^{-1} g x) \overline{b(g)}\\
		&= \frac{1}{|G||H|}\sum_{x \in G}\sum_{g \in G}   \dot{f}(x^{-1} g x) \overline{b(g)}\\
	\end{align*}
	Now let $g = x h x^{-1}$ for $h \in H$ because this is the only time $\dot{f}$ is nonzero.  
	\begin{align*}
		&= \frac{1}{|G||H|}\sum_{x \in G}\sum_{h \in H}   \dot{a}(h) \overline{b(x h x^{-1})}\\
		&= \frac{1}{|G||H|}\sum_{x \in G}\sum_{h \in H}   \dot{a}(h) \overline{b(h)}\\
		&= \frac{1}{|G|}\sum_{x \in G} \frac{1}{|H|}\sum_{h \in H}   a(h) \overline{b(h)}\\
		&= \frac{1}{|G|}\sum_{x \in G} \left\langle a, \res^G_H b \right\rangle\\
		&= \left\langle a, \res^G_H b \right\rangle.
	\end{align*}
\end{proof}
Now, Frobenius reciprocity allows us to prove that induced characters are characters. 

Theorem: Induction maps take characters to characters. 

\subsection{Mackey's theorem}

Two representations $\rho$ and $\psi$ are disjoint if they have no common irreps, meaning that $\left\langle \chi_\rho, \chi_\psi \right\rangle = 0$. 

Let $\rho: H \rightarrow GL_d(\mathbb{C})$ be a rep with $H \leq G$. Then $\ind^G_H \rho$ is irreducible when 
$\left\langle \ind^G_H \chi_\rho , \ind^G_H \chi_\rho \right \rangle = 1$. 

But by Frobenius reciprocity, this is when
\begin{equation}
	\left\langle \chi_\rho , \res^G_H \ind^G_H \chi_\rho \right \rangle = 1.
\end{equation}
But when does this occur?
Consider the double cosets $\doublefaktor{H}{G}{H}$.

We have a result from Mackey. 
\begin{theorem}[Mackey's theorem]
	Let $H, K \leq G$ and let $S$ be a complete set of double coset representatives for $\doublefaktor{H}{G}{K}$. Then:
	\begin{equation}
		\res^G_H \ind^G_K f = \sum_{s \in S} \ind^H_{H \cap s K s^{-1}} \res^{s K s^{-1}}_{H \cap s K s^{-1}} f^s
	\end{equation}
	where $f^s(x) = f(s^{-1} x s)$. 
\end{theorem}

\subsection{Mackey's irreducibility criterion}

We have that if $\rho$ is a rep of $H$, $H \leq G$, then $\rho$ is an irrep of $G$ iff:
\begin{enumerate}
	\item $\rho$ is an irrep of $H$
	\item The reps $\res^H_{H \cap s H s^{-1}} \rho$ and $\res^{s H s^{-1}}_{H \cap s H s^{-1}} \rho^s$ are disjoint for all $s \in \widehat{S}$
\end{enumerate}
where $\widehat{S}$ is the set of coset representatives of $\doublefaktor{H}{G}{H}$. 

\subsubsection{Normal case}
If $H$ is normal, then we only need that:
\begin{theorem}
	$\rho$ and $\rho^s$  are disjoint for all coset representatives $s$ of $G/H$. 
\end{theorem}



\section{Representations of symmetric groups}

We have that for $S_n$, every conjugacy class is equivalent to a cycle type. But every cycle type is also equivalent to a character, and we can associate characters and cycle types.

Denote $\lambda \vdash n$ to say that $\lambda$ is a partition of $n$. 
A Young diagram for a partition $\lambda = (\lambda_1, \lambda_2, ..., \lambda_\ell)$ with weakly decreasing $\lambda_i$ looks like this:

\ydiagram{5, 3, 3, 2}

The young diagrams with 4 boxes are:
\ydiagram{4}, \ydiagram{3,1}, \ydiagram{1,1,1,1}, \ydiagram{2,1,1},  \ydiagram{2,2}.

We say $\lambda$ dominates $\mu$ or $\lambda \unrhd \mu$ if the first $i$ rows have as many boxes as the first $i$ rows of $\mu$ for all $i$. 

Dominance is a partial order. Obviously, $\lambda \unrhd \lambda$, and if $\lambda \unrhd \mu$ and $\mu \unrhd \lambda$, then $\lambda = \mu$. Finally, if $\lambda \unrhd \mu$ and $\mu \unrhd \rho$ then $\lambda \unrhd \rho$. 

\subsection{Young tableaux}
A $\lambda$-tableau where $\lambda \vdash n$ is a way to put the numbers $ 1, ..., n$ in the boxes of the Young diagram for $\lambda$. As an example,
\begin{ytableau}
	1 & 2 & 4\\
	3
\end{ytableau}

For $\lambda \vdash n$, there is a transitive action on $S_n$ on the set of $\lambda$-tableau, which permutes the entries of the square in the obvious way. 

If $t$ is a Young tableau with $n$ boxes, then the column stabiliser of $t$ is the subgroup $C_t \leq S_n$ which preserves the columns of $t$. 

The row stabiliser is the subgroup $R_t \leq S_n$ which preserves the rows of $t$. 

\subsection{Tabloids}
We place an equivalence relation $s \sim t$ if $s$ and $t$ differ by a row stabiliser. Tabloids of shape $\lambda$ is an equivalence class of $\lambda$-tableaux with respect to $\sim$. 

Then the equivalence class is denoted as $[t]$ with $t$ a representative and $T^\lambda$ is the set of $\lambda$-tabloids. 

For $\lambda \vdash n$, there is a well-defined transitive action of $S_n$ on $T^\lambda$ defined as $\sigma[t] = [\sigma t]$ for $t$ a $\lambda$-tableau. 

This is transitive as it is transitive on all $\lambda$-tableaux. It is well defined as if $t_1 \sim t_2$, then we have that no matter how we rearrange the rows of $t_1$, $\sigma$ sends an element in a row to an element in the same row. Therefore, $\sigma t_1 \sim \sigma t_2$. 

We say that $\mathbb{C} T^\lambda$ is the vector space of formal $\mathbb{C}$-linear combinations of $\lambda$-tabloids and $\rho^\lambda$ is the linear extension of the $S_n$ action on $T^\lambda$. We have that $\rho^\lambda$ is generally not irreducible, but the representation of the Young tableau that is dominated appears in $\rho^\lambda$ exactly once. 

Say $A_t : \mathbb{C}T^\lambda \rightarrow  \mathbb{C}T^\lambda$ defined as $A_t = \sum_{\pi \in C_t} \sgn(\pi) \rho^\lambda_\pi$. 
Then $e_t = A_t[t] = \sum_{\pi \in C_t} \sgn(\pi) \pi[t] \in \mathbb{C} T^\lambda$. 

We have that $\rho_\sigma^\lambda e_t = e_{\sigma t}$.

Let $V^\lambda = \Span \lbrace e_t | t$ a $\lambda$-tableau $\rbrace$. This is a $\rho^\lambda$-invariant space of $\mathbb{C} T^\lambda$. Define the Specht representation $\psi^\lambda$ to be the corresponding subrepresentation of $\rho^\lambda: S_n \rightarrow GL(\mathbb{C} T^\lambda)$. 

We want to show that $\psi^\lambda$ forms a complete set of irreps for the symmetric group. 

We have that $\rho^\lambda_\sigma(e_t) = e_{\sigma_t}$. 



\subsection{Four lemmas}
Let $A_t : \mathbb{C}T^\mu \rightarrow \mathbb{C} T^\mu$ by 
\begin{equation}
	A_t = \sum_{\pi \in C_t} \sgn(\pi) \rho^\mu_\pi
\end{equation}

\begin{lemma}[Lemma A]
	Let $s$ be a $\mu$-tableau and $t$ be a $\lambda$-tableau with $\mu, \lambda \vdash n$. If $A_t[s] \neq 0$, then $\lambda \unrhd \mu$. 
\end{lemma}
\begin{proof}
	Suppose that $i, j$ are in the same row of $S$ and in the same column of $t$. Then $(i, j)[s] = [s]$. Let $\sigma_1$, $\sigma_2, ..., \sigma_m$ be the set of coset representatives for $\langle (i, j) \rangle \leq C_t$. Then $A_t[s] = \sum_{\pi \in C_t} \sgn(\pi) \pi[s]$.
	But we can divide it into coset representatives. So we have that this is:
	\begin{align*}
		&= \sum_{i = 1}^m   \sgn(\sigma_k)  \sigma_k[s] + \sgn(\sigma_k \circ (i, j)) [s]\\
		&= \sum_{i = 1}^m   \sgn(\sigma_k) (\sigma_k(s) - \sigma_k \circ(i,j) [s]) = 0
	\end{align*}
\end{proof}
As $A_t[s] \neq 0$, then the entries in the same row of $s$ lie in different columns of $t$. By the dominance lemma, $\lambda \unrhd \mu$. 

\begin{lemma}[Lemma B]
	Let $s$ and $t$ be $\lambda$-tableaux such that entries in the same row of $s$ are in different columns of $t$. Then $A_t[s] = \pm e_t$. 
\end{lemma}
\begin{proof}
	By the corollary of the dominance lemma, there is a $\lambda$-tableau $u$ such that the rows of $u$ contain the same entries as the rows of $s$ and the columns of $u$ contain the same entries as the columns of $t$. So $[u] = [s]$ and there is a $\sigma \in C_t$ such that $\sigma t = u$. 
	So:
	\begin{align*}
		A_t[s] &= \sum_{\pi \in C_t} \sgn(\pi) \pi[s]\\
		&= \sum_{\tau \in C_t} \sgn(\tau \sigma^{-1}) \tau \sigma^{-1} [u]\\
		&= \sgn(\sigma) \sum_{\tau \in C_t} \sgn(\tau) \tau[\sigma^{-1} u]\\
		&= \sgn(\sigma) \sum_{\tau \in C_t} \sgn(\tau) \tau[t]\\
		&= \pm e_t
	\end{align*}
\end{proof}
\begin{lemma}[Lemma C]
	If $t$ is a $\lambda$-tableau, then the image of $A_t$ is $\mathbb{C} e_t$.
\end{lemma}
\begin{proof}
	From lemmas $A$ and $B$, we have that for all $[s] \in T^\lambda$, we have that $A_t[s] = 0$ or $\pm e_t$. 
\end{proof}
Then we equip $\mathbb{C} T^\lambda$ with the inner product for which $T^\lambda$ is orthonormal.
\begin{lemma}[Lemma D]
	If $t$ is a $\lambda$-tableau, the adjoint of $A_t : \mathbb{C} T^\lambda \rightarrow \mathbb{C} T^\lambda$ is $A_t$ itself.
\end{lemma} 
\begin{proof}
	$\rho^\lambda$ is unitary because $\rho^\lambda_\sigma$ permutes the basis vectors in the usual way. So the adjoint satisfies $\rho^\lambda_\sigma)^\star = (\rho^\lambda_\sigma)^{-1} = \rho^\lambda_{\sigma^{-1}}$. 
	For a $\lambda$-tableau, we have that:
	\begin{align*}
		A_t^\star &= \left(\sum_{\pi \in C_t} \sgn(\pi) \rho^\lambda_\pi \right)^\star\\
		&=\sum_{\pi \in C_t} \sgn(\pi) \left(\rho^\lambda_\pi \right)^\star\\
		&= \sum_{\pi \in C_t} \sgn(\pi) \rho^\lambda_{\pi^{-1}}\\
		&= \sum_{\pi \in C_t} \sgn(\pi^{-1}) \rho^\lambda_{\pi^{-1}}\\
		&= A_t.
	\end{align*}
\end{proof}

\subsection{Specht representations are irreducible}
\begin{theorem}[Subrepresentation theorem]
	Let $\lambda \vdash n$ and suppose $W$ is a $\rho^\lambda$-invariant subspace of $\mathbb{C} T^\lambda$. Then either $V^\lambda \subseteq W$ or $W \subseteq (V^\lambda)^\perp$. 
\end{theorem}

Suppose that there is a $\lambda$-tableau $t$ and $v \in W$ such that $A_t v \neq 0$. Then by lemma $C$, we have that $A_t v \in \mathbb{C} e_t$, so $A_t v \in W$. So $\mathbb{C} e_t \cap W \neq 0$. Then we have that $\sigma e_t = e_{\sigma t} \in W$, by the above statement. Since $S_n$ acts transitively on $\lambda$-tableaux, we have $e_t \in W$ for all $\lambda$-tableau $t$. Hence $V^\lambda \subset W$. Now suppose $A_t v = 0$ for all $\lambda$-tableau $t$ and $v \in W$. Then by lemma $D$,
\begin{equation}
	\langle v, e_t \rangle = \langle v, A_t[t] \rangle = \langle A_t v, [t] \rangle = 0
\end{equation}
as $A_t v = 0$. Then as this holds for all $t$ and all $v \in W$, we have that $W \subseteq (V^\lambda)^\perp$. 


\begin{theorem}
	For $\lambda \vdash n$, $\psi^\lambda : S_n \rightarrow GL(V^\lambda)$ is irreducible.
\end{theorem}

\begin{proof}
	Suppose $W$ is a $\psi^\lambda$-invariant subspace of $V^\lambda$. Then either $V^\lambda \subseteq W$, so $W = V^\lambda$, or $W \subset (V^\lambda)^\perp$, which means that $W = 0$. Thus $\psi^\lambda$ is irreducible.
\end{proof}
\subsection{Spect representations are inequivalent}
Let $\lambda, \mu \vdash n$ and let $T \in Hom_{S_n}(\rho^\lambda, \rho^\mu)$. If $V^\lambda \nsubseteq \ker T$, then $\lambda \unrhd \mu$. Moreover...


\section{Lie groups}
Consider a group $G$ that has the structure of a smooth manifold, meaning that group multiplication $G \times G \rightarrow G$ and inversion $G \rightarrow G$ are smooth. 

Lie groups combine topology, representation theory and differential geometry. 

\subsection{Lie algebras}
Take a tangent space at the identity. We can preserve the local structure of the Lie group with the tangent space. The tangent space inherits a `` Lie bracket'' that turns it into a ``Lie algebra'', which is NOT an algebra.

Consider $SL_2(\mathbb{C}) = \left\{
\begin{bmatrix}
	a & b\\
	c & d
\end{bmatrix}
| a, b, c, d \in \mathbb{C}, ad - bc = 1
\right\}
$. 
The tangent space are the matrices that satisfy $\det\left(I + \varepsilon \begin{bmatrix}
	a & b\\
	c & d
\end{bmatrix} \right) \approx 1$, and is denoted $\mathfrak{sl}_2(\mathbb{C})$.  

These are the matrices whose trace is $0$. The associated Lie bracket, therefore, is $\left[A, B\right] = AB - BA$. Note that the trace of $\left[A, B\right]$ is 0, so $[A, B] \in \mathfrak{sl}_2(\mathbb{C})$. 

A Lie algebra is a vector space $\mathfrak{g}$ with operation $\mathfrak{g} \times \mathfrak{g} \rightarrow \mathfrak{g}$ that has the Lie bracket. 

We want that the Lie bracket satisfies:
\begin{enumerate}
	\item Bilinearity
	\item Alternating
	\item Jacobi identity: $[x, [y,z]] + [y, [z, x]] + [z, [x, y]] = 0$. 
\end{enumerate}

\subsection{Lie algebra $\mathfrak{sl}_2(\mathbb{C})$}
Consider operators $E, F, H$ where $E = \begin{bmatrix}
	0 & 1\\
	0 & 0
\end{bmatrix}
$, $F = \begin{bmatrix}
	0 & 0 \\
	1 & 0
\end{bmatrix}
$ and
$ H = \begin{bmatrix}
	1 & 0\\
	0 & -1
\end{bmatrix}
$. This is the fundamental group. 
We have that $[e, f] = h$, $[h, f] = -2f$, $[h, e] = 2e$. 

Now what vector space do these act on?

Consider the vector space $V_d = span\{ x^d, x^{d-1} y, x^{d-2} y^2, ..., x y^{d-1} y^d\}$ as a subspace of polynomials of $x$ and $y$. 

Consider the linear maps $E = x \dfrac{\partial}{\partial y}$, $F = y \dfrac{\partial}{\partial x}$, $H = x \dfrac{\partial}{\partial x} - y \dfrac{\partial}{\partial y}$. 

Then we can show that $V_d$ is an irrep of $\mathfrak{sl}_2(\mathbb{C})$. 
\end{document}
