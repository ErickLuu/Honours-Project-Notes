\documentclass[]{report}
\usepackage[margin=1in]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{url}
\usepackage{todonotes}

% Environments

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}

\numberwithin{theorem}{section}
\numberwithin{equation}{section}

%opening
\title{Representation theory Notes}
\author{Eric Luu}

\begin{document}

\maketitle
\chapter{Representations}
\section{Representations}
A representation of a group $G$ on a vector space $V$ is a map $\rho : G \rightarrow GL(V)$ where $\rho_{g}: V \rightarrow V$ and $\rho_{1} = id$ and $\rho_{g}\rho_{h} x = \rho_{gh} x$. The degree of $\rho$ is dim $V$. The vector spaces that we will be working over are finite-dimensional vector spaces over $\mathbb{C}$, and the groups are finite.

\subsection{Examples}
\begin{enumerate}
	\item Trivial representation: $g \mapsto Id_V$.
	\item Sign representation: $\rho: S_n \rightarrow \mathbb{C}^*$ where $g \mapsto \text{sign}(g)$. 
	\item Natural representation of $S_n \rightarrow GL_n(\mathbb{C})$:
	$g(e_i) = e_{g(i)}$ for $i = 1, 2, ..., n$. The set of permutation matrices of the identity matrix.
	\item Regular representation: For a set $G$, let $V = \text{span}\lbrace e_h : h \in G \rbrace$. Then $\rho_g(e_h) = e_{gh}$ is the left regular representation.
\end{enumerate}
We say that two representations $\rho^1: G \rightarrow GL(V_1)$ and $\rho^2: G \rightarrow GL(V_2)$ are equivalent if there exists an isomorphism $T: V_1 \rightarrow V_2$ such that $\rho^2_g = T \rho^{1}_g T^{-1}$.
\section{Irreducible and indecomposible}
We say a subspace $U \leq V$ is $\rho$-invariant under a representation $\rho: G \rightarrow GL(V)$ if $\rho_g(u) \in U$ for all $u \in U$ and $g \in G$, or in terms of actions, the orbit space of $U$ is $U$. Restricting $\rho$ to $U$ is a subrepresentation.
$\rho: G \rightarrow GL(V)$ is irreducible if the only invariant subspaces are trivial, and reducible otherwise. We say that $V$ is decomposable if $V = V_1 \oplus V_2$ for non-zero invariant subspaces, and indecomposible otherwise.
Note that decomposable implies reducible, and irreducible implies decomposable. Completely reducible implies that we can decompose $V$ into direct sum of subspaces $V_i$ where the representation on $V_i$ is irreducible. 

\begin{theorem}[Matschke's theorem]
	Every representation of a finite group over $\mathbb{C}$ is completely reducible. 
\end{theorem}


We need this lemma to prove Matschke's theorem.

\begin{lemma}
	Let $\rho : G \rightarrow GL(V)$ be a unitary representation, where $G$ is any group and $V$ is over $\mathbb{C}$. Then $\rho$ is irreducible or decomposible. 
\end{lemma}
\begin{proof}
	Consider $\langle \cdot , \cdot \rangle$ as the standard inner product on $V$. We can construct a inner product
	$\langle v,w \rangle_\rho = \sum_{g \in G} \langle \rho_g v , \rho_g w \rangle$
	such that $\rho$ is unitary.
	
Suppose $V$ is unitary. Then $V$ is decomposable. We look at the orthogonal complement of the nontrivial subspace and show that under $\langle \cdot, \cdot \rangle_\rho$, $U^\bot$ is invariant. 

Take $g \in G$, $u \in U$, and $v \in U^\bot$. 
Then:
\begin{equation}
	\langle \rho_g(v), u \rangle = \langle \rho_{g^{-1}} \rho_g v, \rho_{g^{-1}} u \rangle = \langle \rho v, \rho_{g^{-1}} u \rangle = 0
\end{equation}
as $v$ is in $U^\bot$ and $\rho_{g^{-1}} u$ is in $U$. Thus shown decomposability. 
\end{proof}

\begin{proof}[Proof of Matschke's theorem]
	Suppose $\rho$ is a non-zero rep. Then it is equivalent to a unitary rep, so $\rho$ is irreducible or decomposable. Now we induct on the dimension. If $dim V = 1$, then $V$ is irreducible. This handles the base case. Suppose it holds for all $dim V < n$. Then if $V$ has dimension $n + 1$, and $V$ is not irreducible, then $V$ must be decomposable. So $V = U \oplus W$ for invariant subspaces $U$ and $W$. By induction, $U$ and $W$ are completely reducible. Therefore, $V$ is also completely reducible.
\end{proof}
Noe that Matschke's theorem only works when $\langle v,w \rangle_\rho = \sum_{g \in G} \langle \rho_g v , \rho_g w \rangle$ is well-defined. We can use integration over compact groups (matrix integrals) to have similar results. 


\begin{theorem}[Schur's lemma]
	Suppose $\rho$ and $\phi$ be irreducible representations over $\mathbb{C}$. Then the only homomorphisms between $\rho$ and $\phi$ are null-homeomorphisms or scaled isomorphisms. 
\end{theorem}

We use two lemmas to prove this. 
Let $Hom_G( \rho, \phi)$ be the set of morphisms from $\rho$ to $\psi$. We have that:
\begin{lemma}
	$Hom_G( \rho, \phi)$ is a subspace of $Hom(V, W)$. This is because if $S, T \in Hom_G(\rho, \phi)$, $a, b \in \mathbb{C}$, then $(a S + b T) \rho_g = a S \rho_g + b T \rho_g = a \Psi_g S + b \Psi_g T = \psi_g (a S + b T)$. Additionally, the zero map is in $Hom_G( \rho, \phi)$. 
\end{lemma}

We also have that $ker T$ is $\rho$-invariant subspace of $V$, and $im T$ is a $\phi$-invariant subspace of $W$.
\begin{proof}
	$T \rho_g v = \psi_g T v = \psi_g 0 = 0.$. Similarly, if $w \in Im T$ then $w = T v$ for some $v \in V$. Then $\psi_g W = \psi_g T v = T \rho_g v$ is in im T. Thus shown.
\end{proof}

\begin{proof}
	Let $T \in Hom_G( \rho, \phi)$. Since $ker T$ is $\rho$-invariant and $\rho$ is an irrep, $ker T = 0$ or $V$. We also have that since im $T$ is $\phi$-invariant and $\phi$ is an irrep, then $im T = 0$ or $W$. Therefore, $T$ is either the zero map or is an isomorphism. Then we have that if $T$ is an isomorphism, then $\rho \sim \phi$. 
	
	As we are working over $\mathbb{C}$, $T$ has eigenvalue $\lambda$. THen $\lambda I - T$ is not invertible. But we have that $\lambda I - T \in Hom_G(\rho, \rho)$. But this means that $\lambda I - T = 0$, so $T = \lambda I$. 
\end{proof}

By Schur's lemma, all abelian groups have dimension 1. 

\chapter{Algebraic constructions}
\section{New constructions}
We have that if $V$ and $W$ are vector spaces, then the direct sum $V \oplus W$ is a vector space where every element is of the form $v \oplus w$, and obeys the laws that $v_1 \oplus w_1 + v_2 \oplus w_2 = (v_1 + v_2) \oplus (w_1 + w_2)$ and $c (v_1 \oplus w_1) = (c v_1) \oplus (c w_1)$. 

The tensor product $V \otimes W$ is the vector space where $(v_1 + v_2) \otimes w = v_1 \otimes w + v_2 \otimes w$, $v \otimes (w_1 + w_2) = v \otimes w_1 + v \otimes w_2$, $c (v \otimes w) = (cv) \otimes w = v \otimes (cw)$. 


\section{Algebras}
A ring is a structure with an addition and multiplication operator. We have that:
$R$ is an abelian group under addition, so:
\begin{itemize}
	\item $(a + b) + c = a + (b + c)$
	\item $a + b = b + a$
	\item there is an identity such that $a + 0 = a$ for all $a$ in $\mathbb{R}$.
	\item For all $a$ there exists a $-a$ such that $a - a = 0$. 
\end{itemize}
$R$ is a monoid under multiplication, so:
\begin{itemize}
	\item $(a \times b) \times c = a \times (b \times c)$
	\item There exists a $1$ such that $a \times 1 = a = 1 \times a$.
\end{itemize}
Finally, these elements work together nicely, so
\begin{itemize}
	\item $a \times (b + c) = a \times b + a \times c$
	\item $(b + c) \times a = b \times a + c \times a$. 
\end{itemize}

A field is a commutative (so $a \times b = b \times a$) ring where $0 \neq 1$ and all nonzero elements are invertible under multiplication.

An algebra $A$ over a field $K$ is a vector space over $K$ with a bilinear product $A \times A \rightarrow A$ that is bilinear, where:
\begin{itemize}
	\item $(x + y) \cdot z = x \cdot z + y \cdot z$
	\item $x  \cdot (y + z) = x \cdot y + x \cdot z$.
	\item $(cx) \cdot y = x \cdot (cy) = c (x \cdot y)$.
\end{itemize}
We will also assume our algebras are associative, so $(x \cdot y) \cdot z = x \cdot (y \cdot z)$ and unital, so there is a $1 \in A$ such that $1 \cdot x = x \cdot 1 = x$.

\subsection{Examples}
\begin{itemize}
	\item $\mathbb{C}$ under multiplication
	\item $\mathbb{C}[t]$ = complex polynomials under polynomial multiplication
	\item $Mat_n(\mathbb{C})$ is the $n \times n$ complex matrices under matrix multiplication
	\item $\mathbb{C} G$ is a group algebra.
\end{itemize}

A module over a ring $R$ is an abelian group $M$ and an operation $R \times M \rightarrow M$ where:
\begin{itemize}
	\item $r \cdot (x + y) = r \cdot x + r \cdot y$
	\item $(r + s) \cdot x = r \cdot x + s \cdot x$
	\item $(rs )\cdot x = r \cdot (s \cdot x)$
	\item $1 \cdot x = x$
\end{itemize}
for $r, s \in R$, $x, y \in M$.

Essentially, we treat the algebra $A$ as the ring and $V$ as the abelian group to form an $A$-module. There is an algebra homomorphism $\tilde{\rho}: A \rightarrow End(V)$ and we write it as $a \cdot v$. 

\todo{Do symmetric algebras, tensor algebras and exterior algebras}

\subsection{Schur's lemma}
Let $U$ and $V$ be simple $A$-modules, where $A$ is an algebra over $\mathcal{C}$. Then the only homomorphisms between $U$ and $V$ are the null map, or a scaled isomorphism.
\todo{Prove this!}

\subsection{Group algebras}

The group algebra is the algebra that comes from linearising a group $G$. 

\section{Characters}
In mathematics, we can summarise data about a mathematical object that allows us to completely distinguish two objects from each other. Two examples are the Fourier transform and moment-generating functions. 

In representation theory, the summary data that we think about is characters. Characters allow us to build ideas from 
\end{document}
